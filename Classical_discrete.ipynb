{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8090bf9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/conuwoo/.local/lib/python3.8/site-packages/ale_py/roms/__init__.py:89: DeprecationWarning: Automatic importing of atari-py roms won't be supported in future releases of ale-py. Please migrate over to using `ale-import-roms` OR an ALE-supported ROM package. To make this warning disappear you can run `ale-import-roms --import-from-pkg atari_py.atari_roms`.For more information see: https://github.com/mgbellemare/Arcade-Learning-Environment#rom-management\n",
      "  ROMS = resolve_roms()\n",
      "2022-07-27 14:07:39.276344: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
      "2022-07-27 14:07:39.276374: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/conuwoo/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py:546: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "  class IteratorBase(collections.Iterator, trackable.Trackable,\n",
      "/home/conuwoo/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:106: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "  class DatasetV2(collections.Iterable, tracking_base.Trackable,\n",
      "/home/conuwoo/.local/lib/python3.8/site-packages/tensorflow/python/autograph/utils/testing.py:21: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "/home/conuwoo/.local/lib/python3.8/site-packages/keras_preprocessing/image/utils.py:23: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "  'nearest': pil_image.NEAREST,\n",
      "/home/conuwoo/.local/lib/python3.8/site-packages/keras_preprocessing/image/utils.py:24: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  'bilinear': pil_image.BILINEAR,\n",
      "/home/conuwoo/.local/lib/python3.8/site-packages/keras_preprocessing/image/utils.py:25: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  'bicubic': pil_image.BICUBIC,\n",
      "/home/conuwoo/.local/lib/python3.8/site-packages/keras_preprocessing/image/utils.py:28: DeprecationWarning: HAMMING is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.HAMMING instead.\n",
      "  if hasattr(pil_image, 'HAMMING'):\n",
      "/home/conuwoo/.local/lib/python3.8/site-packages/keras_preprocessing/image/utils.py:30: DeprecationWarning: BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX instead.\n",
      "  if hasattr(pil_image, 'BOX'):\n",
      "/home/conuwoo/.local/lib/python3.8/site-packages/keras_preprocessing/image/utils.py:33: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  if hasattr(pil_image, 'LANCZOS'):\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fedd3604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cur_model(num_Conv2D,num_filters,num_kernel,num_lstm_units,num_action, num_frames):\n",
    "  model = Sequential()\n",
    "  model.add(Dense(num_action))  \n",
    "  model.add(LSTM(num_lstm_units)) # LSTM\n",
    "  model.add(Dense(num_action))  \n",
    "  model.compile(loss='mean_squared_error', optimizer='Adam') # model compiles\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43ff6ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinforcement(env, model, n_games=400, epochs=16, epsilon_decrease=0.05, backsight=8):\n",
    "  epsilon = 1 # epsilon allows the model to explore new actions\n",
    "  state_history = []\n",
    "  value_history = []\n",
    "  env.reset() # reset the enviornment state when starting.\n",
    "  obs = env.observation_space.sample() # array with shape (x,) with values corresponding to each observation of the game. x is the number of observation.\n",
    "\n",
    "  for game_number in range(n_games):\n",
    "    states = []\n",
    "    actions = []\n",
    "    values = []\n",
    "    memory = [obs] * backsight # after np.sum(obs,axis=2), shape changes to 2d so reshape it into 3d and divide by (255*3) for standarlization. Then multiply backsight.\n",
    "    # before np.sum, it will be 3d but np.sum will sum every [] inside of the 3d array.\n",
    "    frames = 0\n",
    "\n",
    "    while True:\n",
    "      if random.random() > epsilon: #first state, epsilon will always bigger but because epsilon decreases incrementally during the game, model will favor optimized policy model compare to random action.\n",
    "        action = np.argmax(model.predict(np.array([memory], dtype='float16'))[0]) # LSTM outputs a single value, so choose the first index.\n",
    "      else:\n",
    "        action = env.action_space.sample() # this is random action and outputs discrete integer value i.e. 1\n",
    "      \n",
    "      obs, reward, done, _info = env.step(action) # returns observation_spcae, amount of reward, boolean value if episode has terminated, and info about state.\n",
    "      env.render()  \n",
    "      time.sleep(0.05)\n",
    "      if frames % 1 == 0: # for every 32th frames\n",
    "        print('Game', game_number, 'frame', frames) \n",
    "        actions.append(action) # action taken gets added to the array.\n",
    "        states.append(memory) # obersvation states array gets added to the array/\n",
    "        values.append([0] * env.action_space.n) # if action_space.n = 2, then it will be in a shape of [0,0]\n",
    "        memory.pop(0) # removes the first index from memory array.\n",
    "        memory.append(obs) # and replace with current observation_space. \n",
    "\n",
    "        for i, scores in enumerate(values):\n",
    "          scores[actions[i]] += reward # for example, if there 2 action space, then actions[i] will consist of (0,0),(0,1),(1,0),(1,1). it will then add reward.\n",
    "      \n",
    "      frames += 1 # frames added after every episode.\n",
    "      \n",
    "      if done:\n",
    "        print('Game', game_number, 'lasted', frames, 'frames')\n",
    "        env.reset() # resets state.\n",
    "        break\n",
    "    \n",
    "    state_history.extend(states) # observation states gets added to history.\n",
    "    value_history.extend(values) # value get added to history. \n",
    "    model.fit(np.array(state_history, dtype='float16'), np.array(value_history)) # model.fit(x,y), x is state_history and y is value_history. Thus it's using state_history to predict possible values. Learning occurs here.\n",
    "    epsilon = max(0, epsilon - epsilon_decrease) # eplison decreases until 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "012cbb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/conuwoo/.local/lib/python3.8/site-packages/gym/envs/registration.py:592: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/conuwoo/.local/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/conuwoo/.local/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "2022-07-27 14:07:40.292689: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-07-27 14:07:40.292713: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-27 14:07:40.292733: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (conuwoo-Lenovo-YOGA-920-13IKB): /proc/driver/nvidia/version does not exist\n",
      "2022-07-27 14:07:40.292941: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-27 14:07:40.319888: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1999965000 Hz\n",
      "2022-07-27 14:07:40.320502: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1c8cf10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-07-27 14:07:40.320526: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v0\")\n",
    "model = cur_model(4, 8, 4,8, env.action_space.n, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "170b1498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/conuwoo/.local/lib/python3.8/site-packages/gym/core.py:57: DeprecationWarning: \u001b[33mWARN: You are calling render method, but you didn't specified the argument render_mode at environment initialization. To maintain backward compatibility, the environment will render in human mode.\n",
      "If you want to render in human mode, initialize the environment in this way: gym.make('EnvName', render_mode='human') and don't call the render method.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game 0 frame 0\n",
      "Game 0 frame 1\n",
      "Game 0 frame 2\n",
      "Game 0 frame 3\n",
      "Game 0 frame 4\n",
      "Game 0 frame 5\n",
      "Game 0 frame 6\n",
      "Game 0 frame 7\n",
      "Game 0 frame 8\n",
      "Game 0 frame 9\n",
      "Game 0 frame 10\n",
      "Game 0 frame 11\n",
      "Game 0 frame 12\n",
      "Game 0 frame 13\n",
      "Game 0 frame 14\n",
      "Game 0 frame 15\n",
      "Game 0 frame 16\n",
      "Game 0 frame 17\n",
      "Game 0 frame 18\n",
      "Game 0 frame 19\n",
      "Game 0 frame 20\n",
      "Game 0 frame 21\n",
      "Game 0 frame 22\n",
      "Game 0 frame 23\n",
      "Game 0 frame 24\n",
      "Game 0 frame 25\n",
      "Game 0 frame 26\n",
      "Game 0 frame 27\n",
      "Game 0 lasted 28 frames\n",
      "1/1 [==============================] - 0s 782us/step - loss: 141.2617\n",
      "Game 1 frame 0\n",
      "Game 1 frame 1\n",
      "Game 1 frame 2\n",
      "Game 1 frame 3\n",
      "Game 1 frame 4\n",
      "Game 1 frame 5\n",
      "Game 1 frame 6\n",
      "Game 1 frame 7\n",
      "Game 1 frame 8\n",
      "Game 1 frame 9\n",
      "Game 1 frame 10\n",
      "Game 1 frame 11\n",
      "Game 1 frame 12\n",
      "Game 1 frame 13\n",
      "Game 1 frame 14\n",
      "Game 1 frame 15\n",
      "Game 1 lasted 16 frames\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 105.0814\n",
      "Game 2 frame 0\n",
      "Game 2 frame 1\n",
      "Game 2 frame 2\n",
      "Game 2 frame 3\n",
      "Game 2 frame 4\n",
      "Game 2 frame 5\n",
      "Game 2 frame 6\n",
      "Game 2 frame 7\n",
      "Game 2 frame 8\n",
      "Game 2 frame 9\n",
      "Game 2 frame 10\n",
      "Game 2 frame 11\n",
      "Game 2 frame 12\n",
      "Game 2 frame 13\n",
      "Game 2 frame 14\n",
      "Game 2 lasted 15 frames\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 87.3465\n",
      "Game 3 frame 0\n",
      "Game 3 frame 1\n",
      "Game 3 frame 2\n",
      "Game 3 frame 3\n",
      "Game 3 frame 4\n",
      "Game 3 frame 5\n",
      "Game 3 frame 6\n",
      "Game 3 frame 7\n",
      "Game 3 frame 8\n",
      "Game 3 frame 9\n",
      "Game 3 frame 10\n",
      "Game 3 frame 11\n",
      "Game 3 frame 12\n",
      "Game 3 frame 13\n",
      "Game 3 frame 14\n",
      "Game 3 frame 15\n",
      "Game 3 frame 16\n",
      "Game 3 frame 17\n",
      "Game 3 frame 18\n",
      "Game 3 frame 19\n",
      "Game 3 frame 20\n",
      "Game 3 frame 21\n",
      "Game 3 frame 22\n",
      "Game 3 lasted 23 frames\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 86.8057\n",
      "Game 4 frame 0\n",
      "Game 4 frame 1\n",
      "Game 4 frame 2\n",
      "Game 4 frame 3\n",
      "Game 4 frame 4\n",
      "Game 4 frame 5\n",
      "Game 4 frame 6\n",
      "Game 4 frame 7\n",
      "Game 4 frame 8\n",
      "Game 4 frame 9\n",
      "Game 4 frame 10\n",
      "Game 4 frame 11\n",
      "Game 4 frame 12\n",
      "Game 4 frame 13\n",
      "Game 4 frame 14\n",
      "Game 4 frame 15\n",
      "Game 4 frame 16\n",
      "Game 4 frame 17\n",
      "Game 4 frame 18\n",
      "Game 4 frame 19\n",
      "Game 4 frame 20\n",
      "Game 4 frame 21\n",
      "Game 4 frame 22\n",
      "Game 4 frame 23\n",
      "Game 4 frame 24\n",
      "Game 4 frame 25\n",
      "Game 4 frame 26\n",
      "Game 4 frame 27\n",
      "Game 4 frame 28\n",
      "Game 4 lasted 29 frames\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 102.1438\n",
      "Game 5 frame 0\n",
      "Game 5 frame 1\n",
      "Game 5 frame 2\n",
      "Game 5 frame 3\n",
      "Game 5 frame 4\n",
      "Game 5 frame 5\n",
      "Game 5 frame 6\n",
      "Game 5 frame 7\n",
      "Game 5 frame 8\n",
      "Game 5 frame 9\n",
      "Game 5 frame 10\n",
      "Game 5 frame 11\n",
      "Game 5 frame 12\n",
      "Game 5 frame 13\n",
      "Game 5 frame 14\n",
      "Game 5 frame 15\n",
      "Game 5 frame 16\n",
      "Game 5 frame 17\n",
      "Game 5 frame 18\n",
      "Game 5 frame 19\n",
      "Game 5 frame 20\n",
      "Game 5 frame 21\n",
      "Game 5 frame 22\n",
      "Game 5 frame 23\n",
      "Game 5 frame 24\n",
      "Game 5 frame 25\n",
      "Game 5 frame 26\n",
      "Game 5 frame 27\n",
      "Game 5 frame 28\n",
      "Game 5 frame 29\n",
      "Game 5 frame 30\n",
      "Game 5 frame 31\n",
      "Game 5 frame 32\n",
      "Game 5 frame 33\n",
      "Game 5 frame 34\n",
      "Game 5 frame 35\n",
      "Game 5 frame 36\n",
      "Game 5 lasted 37 frames\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 134.6240\n",
      "Game 6 frame 0\n",
      "Game 6 frame 1\n",
      "Game 6 frame 2\n",
      "Game 6 frame 3\n",
      "Game 6 frame 4\n",
      "Game 6 frame 5\n",
      "Game 6 frame 6\n",
      "Game 6 frame 7\n",
      "Game 6 frame 8\n",
      "Game 6 frame 9\n",
      "Game 6 frame 10\n",
      "Game 6 frame 11\n",
      "Game 6 frame 12\n",
      "Game 6 frame 13\n",
      "Game 6 frame 14\n",
      "Game 6 frame 15\n",
      "Game 6 frame 16\n",
      "Game 6 frame 17\n",
      "Game 6 frame 18\n",
      "Game 6 frame 19\n",
      "Game 6 frame 20\n",
      "Game 6 frame 21\n",
      "Game 6 frame 22\n",
      "Game 6 lasted 23 frames\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 127.6038\n",
      "Game 7 frame 0\n",
      "Game 7 frame 1\n",
      "Game 7 frame 2\n",
      "Game 7 frame 3\n",
      "Game 7 frame 4\n",
      "Game 7 frame 5\n",
      "Game 7 frame 6\n",
      "Game 7 frame 7\n",
      "Game 7 frame 8\n",
      "Game 7 frame 9\n",
      "Game 7 frame 10\n",
      "Game 7 frame 11\n",
      "Game 7 frame 12\n",
      "Game 7 lasted 13 frames\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 120.3751\n",
      "Game 8 frame 0\n",
      "Game 8 frame 1\n",
      "Game 8 frame 2\n",
      "Game 8 frame 3\n",
      "Game 8 frame 4\n",
      "Game 8 frame 5\n",
      "Game 8 frame 6\n",
      "Game 8 frame 7\n",
      "Game 8 frame 8\n",
      "Game 8 frame 9\n",
      "Game 8 frame 10\n",
      "Game 8 frame 11\n",
      "Game 8 frame 12\n",
      "Game 8 frame 13\n",
      "Game 8 lasted 14 frames\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 113.9771\n",
      "Game 9 frame 0\n",
      "Game 9 frame 1\n",
      "Game 9 frame 2\n",
      "Game 9 frame 3\n",
      "Game 9 frame 4\n",
      "Game 9 frame 5\n",
      "Game 9 frame 6\n",
      "Game 9 frame 7\n",
      "Game 9 frame 8\n",
      "Game 9 frame 9\n",
      "Game 9 lasted 10 frames\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 108.8554\n",
      "Game 10 frame 0\n",
      "Game 10 frame 1\n",
      "Game 10 frame 2\n",
      "Game 10 frame 3\n",
      "Game 10 frame 4\n",
      "Game 10 frame 5\n",
      "Game 10 frame 6\n",
      "Game 10 frame 7\n",
      "Game 10 frame 8\n",
      "Game 10 frame 9\n",
      "Game 10 lasted 10 frames\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 104.2175\n",
      "Game 11 frame 0\n",
      "Game 11 frame 1\n",
      "Game 11 frame 2\n",
      "Game 11 frame 3\n",
      "Game 11 frame 4\n",
      "Game 11 frame 5\n",
      "Game 11 frame 6\n",
      "Game 11 frame 7\n",
      "Game 11 frame 8\n",
      "Game 11 frame 9\n",
      "Game 11 frame 10\n",
      "Game 11 frame 11\n",
      "Game 11 frame 12\n",
      "Game 11 frame 13\n",
      "Game 11 frame 14\n",
      "Game 11 lasted 15 frames\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 99.6224\n",
      "Game 12 frame 0\n",
      "Game 12 frame 1\n",
      "Game 12 frame 2\n",
      "Game 12 frame 3\n",
      "Game 12 frame 4\n",
      "Game 12 frame 5\n",
      "Game 12 frame 6\n",
      "Game 12 frame 7\n",
      "Game 12 frame 8\n",
      "Game 12 frame 9\n",
      "Game 12 frame 10\n",
      "Game 12 frame 11\n",
      "Game 12 frame 12\n",
      "Game 12 lasted 13 frames\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mreinforcement\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mreinforcement\u001b[0;34m(env, model, n_games, epochs, epsilon_decrease, backsight)\u001b[0m\n\u001b[1;32m     43\u001b[0m state_history\u001b[38;5;241m.\u001b[39mextend(states) \u001b[38;5;66;03m# observation states gets added to history.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m value_history\u001b[38;5;241m.\u001b[39mextend(values) \u001b[38;5;66;03m# value get added to history. \u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_history\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfloat16\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_history\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# model.fit(x,y), x is state_history and y is value_history. Thus it's using state_history to predict possible values. Learning occurs here.\u001b[39;00m\n\u001b[1;32m     46\u001b[0m epsilon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, epsilon \u001b[38;5;241m-\u001b[39m epsilon_decrease)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:108\u001b[0m, in \u001b[0;36menable_multi_worker.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_method_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    107\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_multi_worker_mode():  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m   \u001b[38;5;66;03m# Running inside `run_distribute_coordinator` already.\u001b[39;00m\n\u001b[1;32m    111\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dc_context\u001b[38;5;241m.\u001b[39mget_current_worker_context():\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1049\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1043\u001b[0m   val_x, val_y, val_sample_weight \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1044\u001b[0m       data_adapter\u001b[38;5;241m.\u001b[39munpack_x_y_sample_weight(validation_data))\n\u001b[1;32m   1046\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy\u001b[38;5;241m.\u001b[39mscope(), \\\n\u001b[1;32m   1047\u001b[0m      training_utils\u001b[38;5;241m.\u001b[39mRespectCompiledTrainableState(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1048\u001b[0m   \u001b[38;5;66;03m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[39;00m\n\u001b[0;32m-> 1049\u001b[0m   data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataHandler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m      \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m      \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m      \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m      \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m      \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m      \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m      \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m      \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1065\u001b[0m   \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py:1105\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1102\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution_value \u001b[38;5;241m=\u001b[39m steps_per_execution\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m   1104\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1119\u001b[0m strategy \u001b[38;5;241m=\u001b[39m ds_context\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[1;32m   1120\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter\u001b[38;5;241m.\u001b[39mget_dataset()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py:362\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    359\u001b[0m     flat_dataset \u001b[38;5;241m=\u001b[39m flat_dataset\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;241m1024\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(epochs)\n\u001b[1;32m    360\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m flat_dataset\n\u001b[0;32m--> 362\u001b[0m indices_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mindices_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslice_batch_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslice_inputs(indices_dataset, inputs)\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:1727\u001b[0m, in \u001b[0;36mDatasetV2.flat_map\u001b[0;34m(self, map_func)\u001b[0m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_map\u001b[39m(\u001b[38;5;28mself\u001b[39m, map_func):\n\u001b[1;32m   1705\u001b[0m   \u001b[38;5;124;03m\"\"\"Maps `map_func` across this dataset and flattens the result.\u001b[39;00m\n\u001b[1;32m   1706\u001b[0m \n\u001b[1;32m   1707\u001b[0m \u001b[38;5;124;03m  Use `flat_map` if you want to make sure that the order of your dataset\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1725\u001b[0m \u001b[38;5;124;03m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[1;32m   1726\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1727\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFlatMapDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:4122\u001b[0m, in \u001b[0;36mFlatMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func)\u001b[0m\n\u001b[1;32m   4120\u001b[0m \u001b[38;5;124;03m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001b[39;00m\n\u001b[1;32m   4121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_dataset \u001b[38;5;241m=\u001b[39m input_dataset\n\u001b[0;32m-> 4122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39moutput_structure, DatasetSpec):\n\u001b[1;32m   4125\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   4126\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`map_func` must return a `Dataset` object. Got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   4127\u001b[0m           \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39moutput_structure)))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:3363\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3355\u001b[0m defun_kwargs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_tf_data_function\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m})\n\u001b[1;32m   3357\u001b[0m \u001b[38;5;66;03m# Note: _wrapper_helper will apply autograph based on context.\u001b[39;00m\n\u001b[1;32m   3358\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;129;43m@eager_function\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefun_with_attributes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_signature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_flat_tensor_specs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3360\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_structure\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefun_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m-> 3363\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mwrapper_fn\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=missing-docstring\u001b[39;49;00m\n\u001b[1;32m   3364\u001b[0m \u001b[43m  \u001b[49m\u001b[43mret\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_wrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3365\u001b[0m \u001b[43m  \u001b[49m\u001b[43mret\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor_list\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_output_structure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mret\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3640\u001b[0m, in \u001b[0;36mdefun_with_attributes.<locals>.decorated\u001b[0;34m(function)\u001b[0m\n\u001b[1;32m   3638\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   3639\u001b[0m   name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 3640\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_decorator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_decorator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mFunction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3643\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3644\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3645\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_signature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3646\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperimental_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperimental_compile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperimental_compile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3650\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperimental_relax_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperimental_relax_shapes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/tf_decorator.py:89\u001b[0m, in \u001b[0;36mmake_decorator\u001b[0;34m(target, decorator_func, decorator_name, decorator_doc, decorator_argspec)\u001b[0m\n\u001b[1;32m     87\u001b[0m   frame \u001b[38;5;241m=\u001b[39m tf_stack\u001b[38;5;241m.\u001b[39mextract_stack(limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     88\u001b[0m   decorator_name \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m---> 89\u001b[0m decorator \u001b[38;5;241m=\u001b[39m \u001b[43mTFDecorator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecorator_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecorator_doc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mdecorator_argspec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28msetattr\u001b[39m(decorator_func, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_tf_decorator\u001b[39m\u001b[38;5;124m'\u001b[39m, decorator)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# Objects that are callables (e.g., a functools.partial object) may not have\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# the following attributes.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/tf_decorator.py:236\u001b[0m, in \u001b[0;36mTFDecorator.__init__\u001b[0;34m(self, decorator_name, target, decorator_doc, decorator_argspec)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTFDecorator\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m    230\u001b[0m   \u001b[38;5;124;03m\"\"\"Base class for all TensorFlow decorators.\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \n\u001b[1;32m    232\u001b[0m \u001b[38;5;124;03m  TFDecorator captures and exposes the wrapped target, and provides details\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;124;03m  about the current decorator.\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    237\u001b[0m                decorator_name,\n\u001b[1;32m    238\u001b[0m                target,\n\u001b[1;32m    239\u001b[0m                decorator_doc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    240\u001b[0m                decorator_argspec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decorated_target \u001b[38;5;241m=\u001b[39m target\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decorator_name \u001b[38;5;241m=\u001b[39m decorator_name\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reinforcement(env, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ed2957",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
